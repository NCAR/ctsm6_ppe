{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "549f19b5-c094-444e-8f1b-9b63ef0a7e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 16:40:52.069963: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-17 16:40:52.211682: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744929652.230230  120753 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744929652.233713  120753 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-17 16:40:52.342033: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import gpflow\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c3485a-adf2-4847-83de-f50cfe1ecadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/glade/u/home/linnia/ctsm6_ppe/')\n",
    "from utils.pyfunctions import *\n",
    "utils_path = '/glade/u/home/linnia/ctsm6_ppe/utils/'\n",
    "from sampling_pyfunctions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a567be3e-425a-4a23-a24a-3a242c3fc181",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client\n",
    "ncores=1\n",
    "nmem='20GB'\n",
    "cluster = PBSCluster(\n",
    "    cores=ncores, # The number of cores you want\n",
    "    memory=nmem, # Amount of memory\n",
    "    processes=1, # How many processes\n",
    "    queue='casper', # The type of queue to utilize (/glade/u/apps/dav/opt/usr/bin/execcasper)\n",
    "    local_directory='$TMPDIR', # Use your local directory\n",
    "    resource_spec='select=1:ncpus='+str(ncores)+':mem='+nmem, # Specify resources\n",
    "    account='P93300041', # Input your project ID here\n",
    "    walltime='02:00:00', # Amount of wall time\n",
    "    #interface='ib0', # Interface to use\n",
    ")\n",
    "\n",
    "# Scale up\n",
    "cluster.scale(10)\n",
    "\n",
    "# Setup your client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19ffff5-f936-46b1-9df2-25a52ed9cf4a",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f87d2cf-0f80-4c33-940e-8166ff3fa3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Setup\n",
    "#############################################\n",
    "# load observational data\n",
    "obs = xr.open_dataset(utils_path+'wave2_obsStatistics_sudokuBiomes.nc')\n",
    "\n",
    "# set parameter info\n",
    "params_lhc = pd.read_csv('/glade/work/linnia/CLM6-PPE/ctsm6_lhc/ctsm6lhc_11262024.txt').drop(columns='member')\n",
    "\n",
    "pft_params   = ['kmax','psi50','jmaxb0','slatop','lmr_intercept_atkin',\n",
    "                'medlynslope','medlynintercept','froot_leaf','leafcn','leaf_long',\n",
    "                'KCN','dleaf','r_mort','fsr_pft','xl']\n",
    "pftix=np.array([p in pft_params for p in params_lhc.columns])\n",
    "u_params = params_lhc.columns[~pftix]\n",
    "\n",
    "pft_param_names = {i: [f\"{param}_{i}\" for param in pft_params] for i in range(1, 15)}\n",
    "\n",
    "# load Biome info\n",
    "with open(utils_path+\"biome_configs.pkl\", \"rb\") as f:\n",
    "    biome_configs = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea24e156-fc7e-4d32-b89b-55d4e0169f7b",
   "metadata": {},
   "source": [
    "### Calibration tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a48fa2-91e5-4935-a002-209c7dc70817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create universal sample\n",
    "from scipy.stats import qmc\n",
    "n_dims = 41\n",
    "n_samples = 100000\n",
    "\n",
    "sampler = qmc.LatinHypercube(d=n_dims)\n",
    "\n",
    "s = sampler.random(n=n_samples)\n",
    "usamples = pd.DataFrame(s,columns=u_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3156049-d1c6-4675-8504-e94dc562344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usamples.to_csv('universal_samples_LHC100000.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de33f601-4db5-4057-b415-47a2f48c706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "usamples = pd.read_csv('universal_samples_LHC10000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6802ce69-92e6-4c27-a1dd-0067d2a3c0a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 15s, sys: 1.29 s, total: 2min 17s\n",
      "Wall time: 2min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "emulator_path = '/glade/u/home/linnia/ctsm6_ppe/analysis_lhc/wave2_biome/emulators_biome'\n",
    "\n",
    "n_psamp = 1000\n",
    "key = np.array(1)\n",
    "n_usets = 10\n",
    "\n",
    "param_sets = []\n",
    "for u in range(key*n_usets,key*n_usets+n_usets):\n",
    "    usample = usamples.iloc[[u]]\n",
    "    psample = pd.DataFrame(np.random.rand(n_psamp,len(pft_params)),columns=pft_params)\n",
    "\n",
    "    b_samples = calibration_tree(usample,psample,n_psamp,u_params,pft_param_names,emulator_path,obs,biome_configs)\n",
    "    # if none of the samples are plausible for any given biome, continue to next universal set\n",
    "    if len(b_samples)==1:\n",
    "        continue\n",
    "    else:\n",
    "        s = create_master_sample(b_samples,pft_param_names)\n",
    "    \n",
    "        param_sets.append(s)\n",
    "\n",
    "master_sample = pd.concat(param_sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6252cb1e-7e33-4a5f-aabf-6c8ae53afafa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/glade/work/linnia/CLM6-PPE/ctsm6_wave1/NROY/hmatch_mastersample_1.csv\n"
     ]
    }
   ],
   "source": [
    "outdir = '/glade/work/linnia/CLM6-PPE/ctsm6_wave1/NROY/'\n",
    "#master_sample.to_csv(out_dir+'hmatch_mastersample_'+str(key)+'.csv',index=False)\n",
    "print(outdir+'hmatch_mastersample_'+str(key)+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlenv]",
   "language": "python",
   "name": "conda-env-mlenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
